{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "557e6170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# Seed for reproducibility\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_name = \"fine-tuned-bart-mlsum-fr-sampled\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Function to summarize text\n",
    "def summarize_text(text, max_length=150, min_length=30):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate the summary\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    \n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Function to handle the summarize button click\n",
    "def summarize():\n",
    "    input_text = input_text_area.get(\"1.0\", tk.END).strip()\n",
    "    if not input_text:\n",
    "        output_text_area.delete(\"1.0\", tk.END)\n",
    "        output_text_area.insert(tk.END, \"Please enter text to summarize.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        detected_language = detect(input_text)\n",
    "    except LangDetectException:\n",
    "        output_text_area.delete(\"1.0\", tk.END)\n",
    "        output_text_area.insert(tk.END, \"Language detection failed. Please enter a valid text.\")\n",
    "        return\n",
    "    \n",
    "    language_label_var.set(f\"Detected Language: {detected_language}\")\n",
    "\n",
    "    if detected_language in [\"fr\", \"de\", \"en\"]:\n",
    "        summary = summarize_text(input_text)\n",
    "    else:\n",
    "        summary = f\"Unsupported language detected: {detected_language}\"\n",
    "\n",
    "    output_text_area.delete(\"1.0\", tk.END)\n",
    "    output_text_area.insert(tk.END, summary)\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Text Summarizer\")\n",
    "\n",
    "# Create and place the input text area\n",
    "input_text_label = tk.Label(root, text=\"Input Text:\")\n",
    "input_text_label.pack()\n",
    "input_text_area = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=10)\n",
    "input_text_area.pack(padx=10, pady=10)\n",
    "\n",
    "# Create and place the summarize button\n",
    "summarize_button = tk.Button(root, text=\"Summarize\", command=summarize)\n",
    "summarize_button.pack(pady=10)\n",
    "\n",
    "# Create and place the language detection label\n",
    "language_label_var = tk.StringVar(value=\"Detected Language: N/A\")\n",
    "language_label = tk.Label(root, textvariable=language_label_var)\n",
    "language_label.pack()\n",
    "\n",
    "# Create and place the output text area\n",
    "output_text_label = tk.Label(root, text=\"Summary:\")\n",
    "output_text_label.pack()\n",
    "output_text_area = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=10)\n",
    "output_text_area.pack(padx=10, pady=10)\n",
    "\n",
    "# Start the main loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc98e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, MarianMTModel, MarianTokenizer\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# Seed for reproducibility\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_name = \"fine-tuned-bart-mlsum-fr-sampled\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Load translation models and tokenizers\n",
    "translation_models = {\n",
    "    \"fr\": {\n",
    "        \"model\": MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\"),\n",
    "        \"tokenizer\": MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\"),\n",
    "    },\n",
    "    \"de\": {\n",
    "        \"model\": MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-de-en\"),\n",
    "        \"tokenizer\": MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-de-en\"),\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to summarize text\n",
    "def summarize_text(text, max_length=150, min_length=30):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate the summary\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    \n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Function to translate text to English\n",
    "def translate_to_english(text, source_lang):\n",
    "    translation_tokenizer = translation_models[source_lang][\"tokenizer\"]\n",
    "    translation_model = translation_models[source_lang][\"model\"]\n",
    "    \n",
    "    inputs = translation_tokenizer.encode(text, return_tensors=\"pt\", truncation=True)\n",
    "    translated_ids = translation_model.generate(inputs, max_length=512, num_beams=4, early_stopping=True)\n",
    "    translated_text = translation_tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return translated_text\n",
    "\n",
    "# Function to handle the summarize button click\n",
    "def summarize():\n",
    "    input_text = input_text_area.get(\"1.0\", tk.END).strip()\n",
    "    if not input_text:\n",
    "        output_text_area.delete(\"1.0\", tk.END)\n",
    "        output_text_area.insert(tk.END, \"Please enter text to summarize.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        detected_language = detect(input_text)\n",
    "    except LangDetectException:\n",
    "        output_text_area.delete(\"1.0\", tk.END)\n",
    "        output_text_area.insert(tk.END, \"Language detection failed. Please enter a valid text.\")\n",
    "        return\n",
    "    \n",
    "    language_label_var.set(f\"Detected Language: {detected_language}\")\n",
    "\n",
    "    if detected_language in [\"fr\", \"de\", \"en\"]:\n",
    "        summary = summarize_text(input_text)\n",
    "        if detected_language != \"en\":\n",
    "            summary = translate_to_english(summary, detected_language)\n",
    "    else:\n",
    "        summary = f\"Unsupported language detected: {detected_language}\"\n",
    "\n",
    "    output_text_area.delete(\"1.0\", tk.END)\n",
    "    output_text_area.insert(tk.END, summary)\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Text Summarizer\")\n",
    "\n",
    "# Create and place the input text area\n",
    "input_text_label = tk.Label(root, text=\"Input Text:\")\n",
    "input_text_label.pack()\n",
    "input_text_area = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=10)\n",
    "input_text_area.pack(padx=10, pady=10)\n",
    "\n",
    "# Create and place the summarize button\n",
    "summarize_button = tk.Button(root, text=\"Summarize\", command=summarize)\n",
    "summarize_button.pack(pady=10)\n",
    "\n",
    "# Create and place the language detection label\n",
    "language_label_var = tk.StringVar(value=\"Detected Language: N/A\")\n",
    "language_label = tk.Label(root, textvariable=language_label_var)\n",
    "language_label.pack()\n",
    "\n",
    "# Create and place the output text area\n",
    "output_text_label = tk.Label(root, text=\"Summary:\")\n",
    "output_text_label.pack()\n",
    "output_text_area = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=10)\n",
    "output_text_area.pack(padx=10, pady=10)\n",
    "\n",
    "# Start the main loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63fa3494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext, filedialog, messagebox\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, BartTokenizer, BartForConditionalGeneration, MarianMTModel, MarianTokenizer, MBartForConditionalGeneration, MBart50Tokenizer\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# Seed for reproducibility\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Load the T5 model and tokenizer for English\n",
    "model_name_en = 't5-small'  # You can also use 't5-base', 't5-large', etc.\n",
    "tokenizer_en = T5Tokenizer.from_pretrained(model_name_en)\n",
    "model_en = T5ForConditionalGeneration.from_pretrained(model_name_en)\n",
    "\n",
    "# Load the fine-tuned BART model and tokenizer for French\n",
    "model_name_fr = \"fine-tuned-bart-mlsum-fr-sampled\"\n",
    "tokenizer_fr = BartTokenizer.from_pretrained(model_name_fr)\n",
    "model_fr = BartForConditionalGeneration.from_pretrained(model_name_fr)\n",
    "\n",
    "# Load the mBART model and tokenizer for German\n",
    "model_name_de = 'facebook/mbart-large-50-many-to-many-mmt'\n",
    "tokenizer_de = MBart50Tokenizer.from_pretrained(model_name_de)\n",
    "model_de = MBartForConditionalGeneration.from_pretrained(model_name_de)\n",
    "\n",
    "# Load translation models and tokenizers\n",
    "translation_models = {\n",
    "    \"fr\": {\n",
    "        \"model\": MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\"),\n",
    "        \"tokenizer\": MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\"),\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to summarize text\n",
    "def summarize_text(text, tokenizer, model, max_length=70, min_length=30, forced_bos_token_id=None, task_prefix=\"summarize: \"):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer.encode(task_prefix + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate the summary\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True, forced_bos_token_id=forced_bos_token_id)\n",
    "    \n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Function to translate text to English\n",
    "def translate_to_english(text, source_lang):\n",
    "    translation_tokenizer = translation_models[source_lang][\"tokenizer\"]\n",
    "    translation_model = translation_models[source_lang][\"model\"]\n",
    "    \n",
    "    inputs = translation_tokenizer.encode(text, return_tensors=\"pt\", truncation=True)\n",
    "    translated_ids = translation_model.generate(inputs, max_length=512, num_beams=4, early_stopping=True)\n",
    "    translated_text = translation_tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return translated_text\n",
    "\n",
    "# Function to handle the summarize button click\n",
    "def summarize():\n",
    "    input_text = input_text_area.get(\"1.0\", tk.END).strip()\n",
    "    if not input_text:\n",
    "        output_text_area.delete(\"1.0\", tk.END)\n",
    "        output_text_area.insert(tk.END, \"Please enter text to summarize.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        detected_language = detect(input_text)\n",
    "    except LangDetectException:\n",
    "        output_text_area.delete(\"1.0\", tk.END)\n",
    "        output_text_area.insert(tk.END, \"Language detection failed. Please enter a valid text.\")\n",
    "        return\n",
    "    \n",
    "    language_label_var.set(f\"Detected Language: {detected_language}\")\n",
    "\n",
    "    if detected_language == \"fr\":\n",
    "        summary = summarize_text(input_text, tokenizer_fr, model_fr)\n",
    "        summary = translate_to_english(summary, \"fr\")\n",
    "    elif detected_language == \"de\":\n",
    "        summary = summarize_text(input_text, tokenizer_de, model_de, forced_bos_token_id=tokenizer_de.lang_code_to_id[\"en_XX\"])\n",
    "    elif detected_language == \"en\":\n",
    "        summary = summarize_text(input_text, tokenizer_en, model_en, task_prefix=\"summarize: \")\n",
    "    else:\n",
    "        summary = f\"Unsupported language detected: {detected_language}\"\n",
    "\n",
    "    output_text_area.delete(\"1.0\", tk.END)\n",
    "    output_text_area.insert(tk.END, summary)\n",
    "\n",
    "# Function to handle the extract text from image button click\n",
    "def extract_text_from_image():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.png;*.jpg;*.jpeg;*.bmp;*.gif\")])\n",
    "    if file_path:\n",
    "        try:\n",
    "            image = Image.open(file_path)\n",
    "            text = pytesseract.image_to_string(image)\n",
    "            input_text_area.delete(\"1.0\", tk.END)\n",
    "            input_text_area.insert(tk.END, text)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Failed to extract text from image. Error: {str(e)}\")\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Text Summarizer\")\n",
    "\n",
    "# Create and place the input text area\n",
    "input_text_label = tk.Label(root, text=\"Input Text:\")\n",
    "input_text_label.pack()\n",
    "input_text_area = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=10)\n",
    "input_text_area.pack(padx=10, pady=10)\n",
    "\n",
    "# Create and place the summarize button\n",
    "summarize_button = tk.Button(root, text=\"Summarize\", command=summarize)\n",
    "summarize_button.pack(pady=10)\n",
    "\n",
    "# Create and place the extract text from image button\n",
    "extract_button = tk.Button(root, text=\"Extract Text from Image\", command=extract_text_from_image)\n",
    "extract_button.pack(pady=10)\n",
    "\n",
    "# Create and place the language detection label\n",
    "language_label_var = tk.StringVar(value=\"Detected Language: N/A\")\n",
    "language_label = tk.Label(root, textvariable=language_label_var)\n",
    "language_label.pack()\n",
    "\n",
    "# Create and place the output text area\n",
    "output_text_label = tk.Label(root, text=\"Summary:\")\n",
    "output_text_label.pack()\n",
    "output_text_area = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=10)\n",
    "output_text_area.pack(padx=10, pady=10)\n",
    "\n",
    "# Start the main loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cca92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
